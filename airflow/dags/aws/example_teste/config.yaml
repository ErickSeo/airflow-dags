default:
  default_args:
    start_date: 2025-07-21
    retries: 1
    retry_delay_sec: 300
  tags: ['aws', 'emr_serveless', 'raw']
  max_active_runs: 1

test_emr_serveless_operator:    
  description: Test EmrServeless Operator
  render_template_as_native_obj: True
  schedule: 8 1 * * *
  owner: ['hiroyukii.seo@gmail.com']
  task_groups:
    raw:
      tooltip: This group process pipeline
      dependencies: []
  tasks:
    raw.built_sync:
      operator: airflow.providers.amazon.aws.operators.datasync.DataSyncOperator
      task_arn: "{{  var.value.built_landing_datasync_arn  }}"
      aws_conn_id: aws_default
      wait_for_completion: True
      task_group_name: raw
      dependencies: []

    raw.spark_dummy:
      operator: airflow.providers.amazon.aws.operators.emr.EmrServerlessStartJobOperator
      application_id: "{{  var.json.emr_serveless_raw.application_id  }}"
      execution_role_arn: "{{  var.json.emr_serveless_raw.execution_role_arn  }}"
      job_driver:
        sparkSubmit:
            entryPoint: s3://builderbinder-datalake-artifacts/datalake_artifacts/raw/dummy/main.py
            entryPointArguments: ['--default_input', '{{ ds }}']
            sparkSubmitParameters: >
              --conf spark.jars=/usr/share/aws/iceberg/lib/iceberg-spark3-runtime.jar
              --conf spark.driver.cores=8
              --conf spark.driver.memory=16g
              --conf spark.executor.cores=4
              --conf spark.executor.memory=8g
              --conf spark.speculation=false
              --conf spark.hadoop.fs.s3a.committer.name=directory
              --conf spark.sql.parquet.fs.optimized.committer.name=directory
              --conf spark.executor.instances=3
      aws_conn_id: aws_default
      wait_for_completion: True
      task_group_name: raw
      dependencies: ['raw.built_sync']